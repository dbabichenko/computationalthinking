{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "print(page.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "print(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Doctype'>\n",
      "<class 'bs4.element.NavigableString'>\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "#[type(item) for item in list(soup.children)]\n",
    "for item in list(soup.children):\n",
    "    print(type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = list(soup.children)[2]\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>,\n",
       " '\\n',\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(html.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <p>Here is some simple content for this page.</p>, '\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(body.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(body.children)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Here is some simple content for this page.</p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for tags by class and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='outer-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"outer-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the web page containing the forecast.\n",
    "* Create a BeautifulSoup class to parse the page.\n",
    "* Find the div with id seven-day-forecast, and assign to seven_day\n",
    "* Inside seven_day, find each individual forecast item.\n",
    "* Extract and print the first forecast item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"tombstone-container\">\n",
      " <p class=\"period-name\">\n",
      "  Tonight\n",
      "  <br/>\n",
      "  <br/>\n",
      " </p>\n",
      " <p>\n",
      "  <img alt=\"Tonight: Mostly cloudy, with a low around 56. West southwest wind 7 to 14 mph, with gusts as high as 18 mph. \" class=\"forecast-icon\" src=\"newimages/medium/nbkn.png\" title=\"Tonight: Mostly cloudy, with a low around 56. West southwest wind 7 to 14 mph, with gusts as high as 18 mph. \"/>\n",
      " </p>\n",
      " <p class=\"short-desc\">\n",
      "  Mostly Cloudy\n",
      " </p>\n",
      " <p class=\"temp temp-low\">\n",
      "  Low: 56 °F\n",
      " </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "seven_day = soup.find(id=\"seven-day-forecast\")\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 pieces of information we can extract:\n",
    "\n",
    "* The name of the forecast item — in this case, Tonight.\n",
    "* The description of the conditions — this is stored in the title property of img.\n",
    "* A short description of the conditions — in this case, Mostly Clear.\n",
    "* The temperature low — in this case, 49 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight\n",
      "Mostly Cloudy\n",
      "Low: 56 °F\n"
     ]
    }
   ],
   "source": [
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "print(period)\n",
    "print(short_desc)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract the title attribute from the img tag. To do this, we just treat the BeautifulSoup object like a dictionary, and pass in the attribute we want as a key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight: Mostly cloudy, with a low around 56. West southwest wind 7 to 14 mph, with gusts as high as 18 mph. \n"
     ]
    }
   ],
   "source": [
    "img = tonight.find(\"img\")\n",
    "desc = img['title']\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to extract each individual piece of information, we can combine our knowledge with css selectors and list comprehensions to extract everything at once.\n",
    "\n",
    "In the below code, we:\n",
    "\n",
    "* Select all items with the class period-name inside an item with the class tombstone-container in seven_day.\n",
    "* Iterate through a list to call the get_text method on each BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tonight',\n",
       " 'Thursday',\n",
       " 'ThursdayNight',\n",
       " 'Friday',\n",
       " 'FridayNight',\n",
       " 'Saturday',\n",
       " 'SaturdayNight',\n",
       " 'Sunday',\n",
       " 'SundayNight']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mostly Cloudy',\n",
       " 'DecreasingClouds',\n",
       " 'IncreasingClouds',\n",
       " 'GradualClearing',\n",
       " 'Partly Cloudy',\n",
       " 'Partly Sunny',\n",
       " 'Partly Cloudy',\n",
       " 'Partly Sunny',\n",
       " 'Partly Cloudy']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_descs = []\n",
    "for sd in seven_day.select(\".tombstone-container .short-desc\"):\n",
    "    short_descs.append(sd.get_text())\n",
    "    \n",
    "short_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = []\n",
    "\n",
    "for t in seven_day.select(\".tombstone-container .temp\"):\n",
    "    temps(t.get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
